{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "from model import *\n",
    "from data import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f09389f6",
   "metadata": {},
   "source": [
    "#### Unpack videos and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86afb5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack_video('data/larynx/train', video_folder='video', image_folder='image/glottis', target_size=(256, 256))\n",
    "unpack_tif('data/larynx/train', tif_folder='tifs', label_folder='label/glottis', target_size=(256, 256))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56ed00c9",
   "metadata": {},
   "source": [
    "#### Initialize the model (U-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a7d141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = unet()\n",
    "# model_checkpoint = ModelCheckpoint('unet_larynx_{epoch:02d}-{loss:.2f}.hdf5', monitor='loss', verbose=1, save_best_only=True)\n",
    "model_checkpoint = ModelCheckpoint('unet_larynx.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a60f9eff",
   "metadata": {},
   "source": [
    "#### Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "\n",
    "splitfolders.ratio(\"data/larynx/train/image\", output=\"data/larynx/train/image_split\",\n",
    "    seed=1234, ratio=(.8, .2), group_prefix=None, move=False) \n",
    "splitfolders.ratio(\"data/larynx/train/label\", output=\"data/larynx/train/label_split\",\n",
    "    seed=1234, ratio=(.8, .2), group_prefix=None, move=False) \n",
    "\n",
    "\n",
    "training_dataset = training_dataset_generator(2,\n",
    "                                              'data/larynx/train/train_dataset/',\n",
    "                                              'image',\n",
    "                                              'label',\n",
    "                                              save_to_dir=None)\n",
    "\n",
    "val_dataset = training_dataset_generator(2,\n",
    "                                              'data/larynx/train/validation_dataset/',\n",
    "                                              'image',\n",
    "                                              'label',\n",
    "                                              save_to_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef560264",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up TensorBoard callback\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model using the training dataset and TensorBoard callback\n",
    "history = model.fit(training_dataset, \n",
    "          steps_per_epoch=10, \n",
    "          epochs=100, \n",
    "          callbacks=[model_checkpoint, tensorboard_callback, early_stopping],\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=10\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca66b6b2",
   "metadata": {},
   "source": [
    "#### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51a041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing the model\n",
    "test_dataset = test_dataset_generator(\"data/larynx/test\", num_image=5)\n",
    "results = model.predict(test_dataset, 3, verbose=1)\n",
    "saveResult(\"data/larynx/test\", results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
